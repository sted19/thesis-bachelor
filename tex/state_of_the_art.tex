\chapter{Stato dell'arte}
Le tecniche principali alla base del progetto sono quelle del rilevamento facciale e riconoscimento facciale. In questo capitolo è descritta la teoria alla base di entrambe.

\section{Rilevamento facciale}
Il metodo di rilevamento facciale utilizzato è uno dei più famosi approcci al problema, ideato da Paul Viola e Michael Jones \cite{viola2001rapid} e successivamente migliorato da Rainer Lienhart \cite{lienhart2002extended}. Si tratta di una procedura di \textit{object detection} basata sul calcolo del valore di semplici features rettangolari, in modo da ottenere un sistema più rapido rispetto ad altri sistemi basati sulla valutazione dei singoli pixel; per quanto riguarda i tempi di computazione il calcolo di queste features è stato reso possibile dall'introduzione dell'immagine integrale, che è un particolare metodo di rappresentazione di un'immagine \cite{viola2001rapid}. Per ottenere la funzione di classificazione è stata scelta una variante di AdaBoost, utilizzata sia per selezionare un gruppo ristretto di features rispetto a tutte quelle esistenti che per addestrare il classificatore \cite{viola2001rapid}. Inoltre è stato possibile ottenere efficienza elevata tramite la struttura a cascata: il classificatore è costituito di svariati classificatori più semplici che vengono applicati uno dopo l'altro ad una regione di interesse, la quale è scartata non appena uno dei classificatori forninsce in output un risultato negativo. In questo modo si è ridotto notevolmente il tempo di calcolo in regioni in cui, fin dalla prima analisi, risulta altamente improbabile che sia presente l'oggetto da rilevare.

\subsection{Tipologia delle features}
Le features semplici utilizzate da Viola-Jones \cite{viola2001rapid} sono di tre tipi: feature composta da due rettangoli, tre rettangoli o quattro rettangoli. In figura \ref{features} si vedono le diverse tipologie di feature; 
\begin{figure}
	\centering
	\includegraphics[width=0.6\linewidth]{./data/images/viola-jones-features.png}
	\caption{Tipologie di features \cite{viola2001rapid}}
	\label{features}
\end{figure}
il loro funzionamento è il seguente: per ogni feature la somma dei pixel che si trovano al di sotto dei rettangoli bianchi è sottratta alla somma dei pixel che si trovano al di sotto dei rettangoli grigi.

\subsection{Immagine Integrale}
L'immagine integrale è una tipologia di rappresentazione delle immagini che ci permette di calcolare il valore di features rettangolari molto rapidamente. Il valore del pixel $x,y$ di un'immagine integrale equivale alla somma dei pixel che si trovano al di sopra e a sinistra di $x,y$ \cite{viola2001rapid}:
\begin{equation}
	ii(x,y)=\sum_{x'\le{x},y'\le{y}}i(x',y') 
\end{equation}
Avendo definito l'immagine integrale in questo modo, il calcolo del valore di una feature rettangolare è immediato: prendendo come esempio l'immagine \ref{integral}, la somma dei pixel nella regione D è semplicemente $ii(4)+ii(1)-ii(2)-ii(3)$.
\begin{figure}
	\centering
	\includegraphics[width=0.6\linewidth]{./data/images/evaluate_rectangular_feature.png}
	\caption{Calcolo di una feature rettangolare a partire da un'immagine integrale \cite{viola2001rapid}}
	\label{integral}
\end{figure}

\subsection{Selezione delle features}
Il numero di features presenti in una regione di soli $24\times24$ pixel è di circa $180,000$, quindi è necessario selezionare solamente le features rilevanti per poter effettuare i calcoli necessari in tempi brevi; una variante dell'algoritmo AdaBoost è stata utilizzata per questo compito, oltre che per il training del classificatore: ci sono dei classificatori deboli che sono basati sulle features rettangolari; questi classificatori vengono addestrati su ogni esempio del dataset. Per ogni feature viene addestrato un classificatore costretto ad utilizzare esclusivamente quella feature; successivamente viene scelto il classificatore che, dopo una valutazione, risulta essere quello con il più piccolo errore, ovvero quello che classifica male il minor numero di esempi. Questo procedimento viene iterato un numero $T$ di volte, aggiornando ogni volta i parametri in base ai risultati ottenuti dal classificatore scelto, fino ad ottenere $T$ classificatori deboli. Il classificatore finale è poi determinato da una somma dei classificatori deboli pesati tramite un valore che dipende dall'errore di classificazione ottenuto da ognuno di essi \cite{viola2001rapid}.

\subsection{Meccanismo a cascata}
In un'immagine generalmente la maggior parte dei pixel non contiene un volto; a partire da questo presupposto, è stato necessario introdurre un meccanismo che evitasse di spendere troppa capacità computazionale per calcolare le features in zone poco interessanti di un'immagine e che allo stesso tempo fosse abbastanza accurato. Il meccanismo a cascata funziona nel seguente modo: ci sono classificatori più semplici e classificatori più complessi che sono posti in cascata in ordine di complessità; i classificatori più semplici sono quelli che analizzano gran parte dell'immagine, scartando la maggior parte delle finestre che avrebbero dato risultato negativo. Le finestre dell'immagine che vengono classificate positivamente vengono poi analizzate dai classificatori più complessi, in modo da eliminare il maggior numero possibile di falsi positivi. In presenza di numerosi classificatori in cascata, una finestra dell'immagine è scartata non appena è classificata in modo negativo, mentre per essere classificata in modo positivo deve essere giudicata tale da ogni classificatore presente nella cascata; in questo modo solo le finestre di un'immagine che danno esito positivo richiederanno di effettuare calcoli complessi, mentre la maggior parte delle altre sarà scartata quasi immediatamente \cite{viola2001rapid}.

\section{Riconoscimento facciale}
Il riconoscimento facciale è stato ottenuto in due passaggi:
\begin{enumerate}
	\item rappresentazione dell'immagine come un array di features;
	\item classificazione dell'array di features tramite un algoritmo di classificazione.
\end{enumerate}
E' stata utilizzata una \textbf{rete neurale convoluzionale} per l'estrazione delle features dall'immagine di un volto, mentre invece l'algoritmo di classificazione utilizzato è stato quello del \textbf{k Nearest Neighbors (kNN)}. 

\subsection{Reti neurali}
In questa sezione si presenta il concetto di rete neurale feedforward, in particolare viene approfondita la tipologia di rete neurale convoluzionale. 
Una rete neurale feedforward descrive il modo in cui diverse funzioni sono composte fra loro ed è di solito rappresentata da un grafo aciclico diretto come quello in figura \ref{feedforward}. L'obiettivo di una rete neurale è quello di approssimare al meglio una determinata funzione $f^{*}$. Se la funzione complessiva che descrive una rete è $f(\pmb{x})$, ogni layer (o strato) della rete rappresenta una funzione del tipo $f^{(1)}(\pmb{x})$ e una rete composta da tre layer sarà tale per cui vale $f(\pmb{x})=f^{(3)}(f^{(2)}(f^{1}(\pmb{x})))$ \cite{goodfellow2016deep}.
\begin{figure}
	\centering
	\includegraphics[width=0.5\linewidth]{./data/images/feedforward_neural_network.png}
	\caption{Esempio di rete neurale di tipo feedforward; a sinistra è stata disegnata ogni unità (o neurone) della rete, mentre a destra ogni nodo del grafo rappresenta un intero layer della rete. La rete rappresentata in figura è composta da un solo hidden layer.  \cite{goodfellow2016deep}.}
	\label{feedforward}
\end{figure}
Il primo layer della rete è chiamato \textit{input layer} e l'ultimo è chiamato \textit{output layer}, mentre i layer intermedi sono chiamati \textit{hidden layers}. 
Una rete neurale convoluzionale (CNN) è un particolare tipo di rete neurale feedforward in cui è presente  almeno un layer di tipo convoluzionale, ovvero un layer che utilizza l'operazione di convoluzione.

\subsubsection{Operazione di convoluzione}
La convoluzione è un'operazione matematica definita fra due funzioni di valori reali \cite{goodfellow2016deep}:
\begin{equation}
	s(t)=\int{x(a)w(t-a)da}
	\label{integral_convolution}
\end{equation}
Nel caso discreto l'operazione di convoluzione diventa la seguente \cite{goodfellow2016deep}:
\begin{equation}
	s(t)=\sum_{a=-\infty}^{\infty}{x(a)w(t-a)}
	\label{discrete_convolution}
\end{equation}
Il primo argomento, $x$ in \ref{integral_convolution} e \ref{discrete_convolution}, è chiamato input della convoluzione, mentre il secondo argomento, $w$ in \ref{integral_convolution} e \ref{discrete_convolution}, è chiamato kernel.
Per quanto riguarda applicazioni di Machine Learning, la convoluzione generalmente ha come input e output tensori, ovvero array multidimensionali; sfruttando la sua proprietà di commutatività può essere scritta nel seguente modo \cite{goodfellow2016deep}:
\begin{equation}
	S(i,j)=\sum_{m}{\sum_{n}{I(i-m,j-n)K(m,n)}}
	\label{multidimensional_convolution}
\end{equation}
La maggior parte delle librerie di Machine Learning utilizzano però un'operazione chiamata \textit{cross-correlation}, molto simile alla convoluzione, che è la seguente \cite{goodfellow2016deep}:
\begin{equation}
S(i,j)=\sum_{m}{\sum_{n}{I(i+m,j+n)K(m,n)}}
\label{cross-correlation}
\end{equation}
La figura \ref{convolution} mostra graficamente l'operazione di \textit{cross-correlation} con input, kernel e output multidimensionali in modo da rendere più chiaro il funzionamento di un layer convoluzionale di una CNN.
\begin{figure}
	\centering
	\includegraphics[width=0.6\linewidth]{./data/images/convolution.png}
	\caption{Operazione di \textit{cross-correlation} in due dimensioni \cite{goodfellow2016deep} }
	\label{convolution}
\end{figure}


\iffalse
\subsubsection{Layer convoluzionale}
Un layer convoluzionale è un array di \textit{feature-maps}; una \textit{feature-map} è una matrice di neuroni; neuroni appartenenti alla stessa \textit{feature-map} sono caratterizzati dagli stessi pesi; questa è una caratteristica molto importante di un layer convoluzionale, perché, oltre a diminuire il numero di parametri rispetto ai classici layer \textit{fully-connected}, rende la rete invariante rispetto alle traslazioni dell'input: essendo i pesi di ogni neurone identici in una stessa \textit{feature-map}, ogni neurone reagirà allo stesso modo a stessi valori di input in qualsiasi zona dell'immagine essi si trovino.
\fi

\subsection{k Nearest Neighbors}
Un algoritmo di Nearest Neighbors si basa sull'assunzione che le features utilizzate per effettuare una classificazione sono distribuite in modo tale che la distanza fra esse sia rilevante alla classificazione e che punti vicini fra loro siano più probabilmente appartenenti alla stessa classe rispetto a punti che invece sono lontani fra loro \cite{shalev2014understanding}. 

\subsubsection{Formulazione matematica del kNN} 
Assumiamo di avere un dominio $X$ su cui è definita una metrica $\rho$ tale che $\rho:X\times X \mapsto \mathbb{R}$ è una funzione che ritorna la distanza fra due elementi di $X$. Sia $S=(\pmb{x}_{1},y_{1}),\dots,(\pmb{x}_{m},y_{m})$ una sequenza di esempi $\pmb{x}_{i}$ con le rispettive classi $y_{i}$ e sia $\pi_{1}(\pmb{x}),\dots,\pi_{m}(\pmb{x})$ un riordinamento di $\{1,\dots,m\}$ basato sulla distanza da $\pmb{x}$, così che, per ogni $i<m$, vale la seguente \cite{shalev2014understanding}:
\begin{equation}
	\rho(\pmb{x},\pmb{x}_{\pi_{i}(\pmb{x})}) \le \rho(\pmb{x},\pmb{x}_{\pi_{i+1}(\pmb{x})}).
\end{equation}
Per un qualsiasi numero $k$ possiamo quindi definire una regola di classificazione nel seguente modo: se in input abbiamo una sequenza di esempi definita come sopra, per ogni punto $\pmb{x}\in X$ l'algoritmo ritorna la classe maggiormente presente fra gli elementi di $\{y_{\pi_{i}(\pmb{x})} : i \le k\}$ \cite{shalev2014understanding}. In base alla regola così definita, se per esempio $k=1$, se $h_{S}(\pmb{x})$ è il risultato dell'algoritmo, abbiamo che per l' 1-NN la regola di decisione sarà semplicemente
\begin{equation}
	h_{S}(\pmb{x}) = y_{\pi_{1}(\pmb{x})}.
\end{equation} 
\begin{figure}
	\centering
	\includegraphics[width=0.6\linewidth]{./data/images/voronoi_tessellation.png}
	\caption{Illustrazione grafica della regola di decisione ottenuta per l'1-NN. Per ogni nuovo punto la classe predetta dall'algoritmo sarà la classe del punto del dataset all'interno della cella a cui appartiene il punto appena introdotto \cite{shalev2014understanding}}
	\label{voronoi}
\end{figure}

\section{Lavori precedenti}
Algoritmi di classificazione di Machine Learning sono stati già utilizzati precedentemente per ottenere il risultato del riconoscimento facciale, come dimostra l'articolo di Pallabi Parveen e Bhavani Thuraisingham in cui sono anche stati messi a confronto vari algoritmi come kNN e SVM per misurarne l'efficienza e l'accuratezza al fine di ottenere un valido sistema di riconoscimento facciale real-time. \cite{parveen2006face}.

